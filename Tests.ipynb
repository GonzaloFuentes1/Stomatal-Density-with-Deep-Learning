{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1727112372941,
     "user": {
      "displayName": "Gonzalo Fuentes",
      "userId": "02144207982774235237"
     },
     "user_tz": 180
    },
    "id": "Kec5agKoIbi-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata para ordenar el entrenamiento\n",
    "metadata_path = 'datasets\\Labeled Stomatal Images.csv'\n",
    "metadata = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediciones 1 plant-out\n",
    "def onePlantOut(plant_name):\n",
    "  main_folder = 'datasets'\n",
    "\n",
    "  train_images_folder = os.path.join(main_folder, 'train/images')\n",
    "  train_labels_folder = os.path.join(main_folder, 'train/labels')\n",
    "  val_images_folder = os.path.join(main_folder, 'val/images')\n",
    "  val_labels_folder = os.path.join(main_folder, 'val/labels')\n",
    "\n",
    "  folders = [train_images_folder, train_labels_folder, val_images_folder, val_labels_folder]\n",
    "\n",
    "  # Sino existen los directorios\n",
    "  for folder in folders:\n",
    "      if not os.path.exists(folder):\n",
    "          os.makedirs(folder)\n",
    "\n",
    "  # Seleccionar la planta a medir su rendimiento\n",
    "  plant = plant_name\n",
    "  trainFiles = metadata[metadata['Species'] != plant]['FileName'].tolist()\n",
    "  valFiles = metadata[metadata['Species'] == plant]['FileName'].tolist()\n",
    "\n",
    "  for folder in folders:\n",
    "    for file in os.listdir(folder):\n",
    "      if file.split(\".\")[0] in trainFiles:\n",
    "        if file.endswith(\".jpg\"):\n",
    "          shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'train/images', file))\n",
    "        elif file.endswith(\".txt\"):\n",
    "          shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'train/labels', file))\n",
    "\n",
    "  for folder in folders:\n",
    "    for file in os.listdir(folder):\n",
    "      if file.split(\".\")[0] in valFiles:\n",
    "        if file.endswith(\".jpg\"):\n",
    "          shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'val/images', file))\n",
    "        elif file.endswith(\".txt\"):\n",
    "          shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'val/labels', file))\n",
    "\n",
    "def holdOut(random_seed = 42, test_size = 0.2):\n",
    "    random.seed(random_seed)\n",
    "    main_folder = 'datasets'\n",
    "\n",
    "    train_images_folder = os.path.join(main_folder, 'train/images')\n",
    "    train_labels_folder = os.path.join(main_folder, 'train/labels')\n",
    "    val_images_folder = os.path.join(main_folder, 'val/images')\n",
    "    val_labels_folder = os.path.join(main_folder, 'val/labels')\n",
    "\n",
    "    folders = [train_images_folder, train_labels_folder, val_images_folder, val_labels_folder]\n",
    "\n",
    "  # Sino existen los directorios\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    # Obtener todos los archivos de la columna 'FileName'\n",
    "    all_files = metadata['FileName'].tolist()\n",
    "\n",
    "    # Mezclar aleatoriamente los archivos\n",
    "    random.shuffle(all_files,)\n",
    "\n",
    "    split_idx = int((1-test_size) * len(all_files))\n",
    "    trainFiles = all_files[:split_idx]\n",
    "    valFiles = all_files[split_idx:]\n",
    "\n",
    "    for folder in folders:\n",
    "        for file in os.listdir(folder):\n",
    "            if file.split(\".\")[0] in trainFiles:\n",
    "                if file.endswith(\".jpg\"):\n",
    "                    shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'train/images', file))\n",
    "                elif file.endswith(\".txt\"):\n",
    "                    shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'train/labels', file))\n",
    "    \n",
    "    for folder in folders:\n",
    "        for file in os.listdir(folder):\n",
    "            if file.split(\".\")[0] in valFiles:\n",
    "                if file.endswith(\".jpg\"):\n",
    "                    shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'val/images', file))\n",
    "                elif file.endswith(\".txt\"):\n",
    "                    shutil.move(os.path.join(folder, file), os.path.join(main_folder, 'val/labels', file))\n",
    "                    \n",
    "def plot_detections(results):\n",
    "    img_rgb = cv2.cvtColor(results.orig_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(img_rgb)\n",
    "    for box, score in zip(results.boxes.xyxy, results.boxes.conf):\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Coordenadas deben ser ints\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Mostrar el score como etiqueta en la esquina superior izquierda de la caja\n",
    "        label = f\"{score:.2f}\"  # Formatear el score a 2 decimales\n",
    "        ax.text(x1, y1, label, color='white', fontsize=5, verticalalignment='top', bbox={'color': 'r', 'pad': 0})\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "def show_image(image_path, txt_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Leer y mostrar el contenido del archivo .txt\n",
    "    with open(txt_path, 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "\n",
    "    for annotation in annotations:\n",
    "        class_id, x_center, y_center, width, height = map(float, annotation.split())\n",
    "        x = (x_center - width / 2) * img.shape[1]\n",
    "        y = (y_center - height / 2) * img.shape[0]\n",
    "        w = width * img.shape[1]\n",
    "        h = height * img.shape[0]\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipo de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir el tipo de preprocesamiento\n",
    "holdOut(random_seed = 42, test_size = 0.2)\n",
    "# onePlantOut(\"Nuttall oak\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model8 = YOLO('Modelos\\yolov8\\HoldOutSimpleYolov8n.pt')\n",
    "model8Adjust = YOLO('Modelos\\yolov8\\HoldOutAdjustYolov8n.pt')\n",
    "model10 = YOLO('Modelos\\yolov10\\HoldOutSimpleYolov10n.pt')\n",
    "model10Adjust = YOLO('Modelos\\yolov10\\HoldOutAdjustYolov10n.pt')\n",
    "\n",
    "ReTrainModel10 = YOLO(\"Modelos\\yolov10\\HoldOutSimpleYolov10nRETRAIN.pt\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_images = \"datasets/train/images\"\n",
    "PATH_labels = \"datasets/train/labels\"\n",
    "plant_type = '/STMHD'\n",
    "number = \"0002\"\n",
    "image_path = f\"{PATH_images}{plant_type}{number}.jpg\"\n",
    "txt_path = f\"{PATH_labels}{plant_type}{number}.txt\"\n",
    "\n",
    "results = model10.predict(image_path)[0]\n",
    "\n",
    "show_image(image_path, txt_path)\n",
    "plot_detections(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test mÃ©tricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results8 = model8.val(data='YOLO8INFO.yaml', save_json=False)\n",
    "results8Adjust = model8Adjust.val(data='YOLO8INFO.yaml', save_json=False)\n",
    "results10 = model10.val(data='YOLO8INFO.yaml', save_json=False)\n",
    "results10Adjust = model10Adjust.val(data='YOLO8INFO.yaml', save_json=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bounding_boxes(model, image_path, confidence_threshold):\n",
    "    results = model.predict(image_path, verbose=False)\n",
    "    bbox_counts = defaultdict(int)\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes: \n",
    "            if box.conf >= confidence_threshold: \n",
    "                class_id = int(box.cls) \n",
    "                bbox_counts[class_id] += 1\n",
    "\n",
    "    return bbox_counts\n",
    "\n",
    "def load_labels(label_path):\n",
    "    labels = defaultdict(list)\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            bbox = list(map(float, parts[1:]))\n",
    "            labels[class_id].append(bbox)\n",
    "    return labels\n",
    "\n",
    "def calculate_differences(pred_counts, real_counts):\n",
    "    differences = {} \n",
    "\n",
    "    all_classes = set(pred_counts.keys()).union(set(real_counts.keys()))\n",
    "\n",
    "    for class_id in all_classes:\n",
    "        real_count = real_counts.get(class_id, 0)\n",
    "        pred_count = pred_counts.get(class_id, 0)\n",
    "\n",
    "        difference = pred_count - real_count\n",
    "        differences[class_id] = difference\n",
    "\n",
    "    return differences\n",
    "\n",
    "# Confidence Threshold de yolo es 0.25 por defecto\n",
    "def compare_predictions_with_labels(model, image_path, label_path, confidence_threshold = 0.25): \n",
    "\n",
    "    pred_counts = count_bounding_boxes(model, image_path, confidence_threshold)\n",
    "\n",
    "    real_labels = load_labels(label_path)\n",
    "\n",
    "    real_counts = {class_id: len(bboxes) for class_id, bboxes in real_labels.items()}\n",
    "\n",
    "    differences_by_class = calculate_differences(pred_counts, real_counts)\n",
    "\n",
    "    return differences_by_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = count_bounding_boxes(model8,image_path,confidence_threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'datasets/val/images'\n",
    "label_dir = 'datasets/val/labels'\n",
    "\n",
    "images = [img for img in os.listdir(image_dir) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "differences8 = []\n",
    "differences8Adjust = []\n",
    "differences10 = []\n",
    "differences10Adjust = []\n",
    "\n",
    "for image_name in tqdm(images):\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    label_path = os.path.join(label_dir, image_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "    differences8_by_class = compare_predictions_with_labels(model8, image_path, label_path)\n",
    "    differences8.append(differences8_by_class)\n",
    "    differences8Adjust_by_class = compare_predictions_with_labels(model8Adjust, image_path, label_path)\n",
    "    differences8Adjust.append(differences8Adjust_by_class)\n",
    "    differences10_by_class = compare_predictions_with_labels(model10, image_path, label_path)\n",
    "    differences10.append(differences10_by_class)\n",
    "    differences10Adjust_by_class = compare_predictions_with_labels(model10Adjust, image_path, label_path)\n",
    "    differences10Adjust.append(differences10Adjust_by_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(differences):\n",
    "    media = np.mean(differences)\n",
    "    mediana = np.median(differences)\n",
    "    desviacion_estandar = np.std(differences)\n",
    "    varianza = np.var(differences)\n",
    "    rango = np.ptp(differences)\n",
    "    minimo = np.min(differences)\n",
    "    maximo = np.max(differences)\n",
    "    sesgo = stats.skew(differences)\n",
    "    curtosis = stats.kurtosis(differences)\n",
    "    \n",
    "    return {\n",
    "        \"media\": media,\n",
    "        \"mediana\": mediana,\n",
    "        \"desviacion_estandar\": desviacion_estandar,\n",
    "        \"varianza\": varianza,\n",
    "        \"rango\": rango,\n",
    "        \"minimo\": minimo,\n",
    "        \"maximo\": maximo,\n",
    "        \"sesgo\": sesgo,\n",
    "        \"curtosis\": curtosis\n",
    "    }\n",
    "\n",
    "def flatten_differences_by_class(differences):\n",
    "    class_differences = defaultdict(list)\n",
    "    for diff in differences:\n",
    "        for class_id, value in diff.items():\n",
    "            class_differences[class_id].append(value)\n",
    "    return class_differences\n",
    "\n",
    "def calculate_and_print_stats_by_class(flat_differences):\n",
    "    for class_id, diffs in flat_differences.items():\n",
    "        stats_by_class = calculate_statistics(diffs)\n",
    "        print(f\"Clase {class_id}:\")\n",
    "        print(stats_by_class)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_differences8 = flatten_differences_by_class(differences8)\n",
    "flat_differences8Adjust = flatten_differences_by_class(differences8Adjust)\n",
    "flat_differences10 = flatten_differences_by_class(differences10)\n",
    "flat_differences10Adjust = flatten_differences_by_class(differences10Adjust)\n",
    "\n",
    "print(\"MÃ©tricas estadÃ­sticas por clase para model8:\")\n",
    "calculate_and_print_stats_by_class(flat_differences8)\n",
    "\n",
    "print(\"MÃ©tricas estadÃ­sticas por clase para model8Adjust:\")\n",
    "calculate_and_print_stats_by_class(flat_differences8Adjust)\n",
    "\n",
    "print(\"MÃ©tricas estadÃ­sticas por clase para model10:\")\n",
    "calculate_and_print_stats_by_class(flat_differences10)\n",
    "\n",
    "print(\"MÃ©tricas estadÃ­sticas por clase para model10Adjust:\")\n",
    "calculate_and_print_stats_by_class(flat_differences10Adjust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Re-Entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results10Retrain = ReTrainModel10.val(data='YOLO8INFO.yaml', save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'datasets/val/images'\n",
    "label_dir = 'datasets/val/labels'\n",
    "\n",
    "images = [img for img in os.listdir(image_dir) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "differences = []\n",
    "\n",
    "for image_name in tqdm(images):\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    label_path = os.path.join(label_dir, image_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "    differences_by_class = compare_predictions_with_labels(ReTrainModel10, image_path, label_path)\n",
    "    differences.append(differences_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_differences = flatten_differences_by_class(differences)\n",
    "\n",
    "print(\"MÃ©tricas estadÃ­sticas por clase:\")\n",
    "calculate_and_print_stats_by_class(flat_differences)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
